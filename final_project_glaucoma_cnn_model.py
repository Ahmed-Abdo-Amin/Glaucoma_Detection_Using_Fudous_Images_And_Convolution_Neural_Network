# -*- coding: utf-8 -*-
"""Final_project_Glaucoma_CNN_Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fRPwGfCvRtzY-UnkLsIwOwziNA212pDb

## Importing the libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import tensorflow as tf
from keras.preprocessing.image import ImageDataGenerator 
from google.colab import drive
import matplotlib.pyplot as plt
import glob 
from numpy import asarray
from PIL import Image
import os 
import cv2
from PIL import Image
from skimage.transform import resize 
import skimage
from skimage import io 
from sklearn.metrics import confusion_matrix, classification_report
# %matplotlib inline

"""## Importing the dataset"""

drive.mount('/content/drive')
train_set = '/content/drive/MyDrive/Final_data/train'
test_set = '/content/drive/MyDrive/Final_data/test'
validation_set = '/content/drive/MyDrive/Final_data/validation'

"""## Image preprocessing"""

class_names_train = os.listdir((train_set))
class_names_train

img_path_train_class0 = os.path.join(train_set, class_names_train[0], '*')
img_path_train_class0 = glob.glob(img_path_train_class0)
mg_path_train_class1 = os.path.join(train_set, class_names_train[1], '*')
img_path_train_class1 = glob.glob(mg_path_train_class1)

class_names_test = os.listdir((test_set))
class_names_test

img_path_test_class0 = os.path.join(test_set, class_names_test[1], '*')
img_path_test_class0 = glob.glob(img_path_test_class0)
mg_path_test_class1 = os.path.join(test_set, class_names_test[0], '*')
img_path_test_class1 = glob.glob(mg_path_test_class1)

class_names_validation = os.listdir((validation_set))
class_names_validation

img_path_validation_class0 = os.path.join(validation_set, class_names_validation[0], '*')
img_path_validation_class0 = glob.glob(img_path_validation_class0)
mg_path_validation_class1 = os.path.join(validation_set, class_names_validation[1], '*')
img_path_validation_class1 = glob.glob(mg_path_validation_class1)

image = io.imread(img_path_train_class0[1]) 
print(image.shape)

def image_preprocess (image_path,folder_path):
  # dsize = (500,300)
  c =1
  for img in image_path:
    pic = cv2.imread(img,0)
    # pic = cv2.resize(pic, dsize, interpolation = cv2.INTER_AREA)
    pic = cv2.GaussianBlur(pic, (5,5), cv2.BORDER_DEFAULT)
    norm_image = (pic - np.min(pic)) / (np.max(pic) - np.min(pic))
    dir = folder_path.format(c)
    plt.imsave(dir,norm_image)
    c+=1

# train_pre_class0 = image_preprocess(img_path_train_class0,"/content/drive/MyDrive/preprocessed_images/train/class0/img{:.2f}.jpg")
# train_pre_class1 = image_preprocess(img_path_train_class1,"/content/drive/MyDrive/preprocessed_images/train/class1/img{:.2f}.jpg")
# test_pre_class0 = image_preprocess(img_path_test_class0,"/content/drive/MyDrive/preprocessed_images/test/class0/img{:.2f}.jpg")
# test_pre_class1 = image_preprocess(img_path_test_class1,"/content/drive/MyDrive/preprocessed_images/test/class1/img{:.2f}.jpg")

# validation_pre_class0 = image_preprocess(img_path_validation_class0,"/content/drive/MyDrive/preprocessed_images/validation/class0/img{:.2f}.jpg")
# validation_pre_class1 = image_preprocess(img_path_validation_class1,"/content/drive/MyDrive/preprocessed_images/validation/class1/img{:.2f}.jpg")

"""# CNN model"""

import tensorflow as tf
import keras_preprocessing
from keras_preprocessing import image
from keras_preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers
from tensorflow.keras import Model

TRAINING_DIR = "/content/drive/MyDrive/Preprocessed_Images/train"
training_datagen = ImageDataGenerator(
      rescale = 1./255,
	    rotation_range=20,
      width_shift_range=0.2,
      height_shift_range=0.2,
      shear_range=0.2,
      zoom_range=0.2,
      horizontal_flip=True,
      fill_mode='nearest',
      vertical_flip=True,
      brightness_range=[0.5,2.0],
      featurewise_center =True,
      featurewise_std_normalization = True)

TEST_DIR = "/content/drive/MyDrive/Preprocessed_Images/test"
testing_datagen = ImageDataGenerator(rescale = 1./255)

VALIDATION_DIR = "/content/drive/MyDrive/Preprocessed_Images/validation"
validation_datagen = ImageDataGenerator(rescale = 1./255)

train_generator = training_datagen.flow_from_directory(
	TRAINING_DIR,
  target_size=(150,150),
  batch_size=23,	
  class_mode = 'binary'
  )

test_generator = testing_datagen.flow_from_directory(
	TEST_DIR,
  target_size = (150, 150),
  batch_size = 23,
  class_mode = 'binary'
  )

validation_generator = validation_datagen.flow_from_directory(
	VALIDATION_DIR,
  batch_size=20,
	target_size=(150,150),
	class_mode = 'binary'
  )

model = tf.keras.models.Sequential([
    # Note the input shape is the desired size of the image 150x150 with 3 bytes color
    # This is the first convolution
    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=[150, 150, 3]),
    tf.keras.layers.MaxPooling2D(2, 2),
    # The second convolution
    tf.keras.layers.Conv2D(32, 3, activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    # The third convolution
    tf.keras.layers.Conv2D(128, 3, activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    # The fourth convolution
    tf.keras.layers.Conv2D(128, 3, activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    # Flatten the results to feed into a DNN
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dropout(0.1),
    tf.keras.layers.Flatten(),
    # 512 neuron hidden layer
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])


model.summary()

model.compile(loss = 'binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])

history = model.fit(x=train_generator, epochs=50,validation_data = validation_generator)

model.save("Glaucoma_dataset.h5")
print(history)

score = model.evaluate_generator(test_generator) 
print(" Total: ", len(test_generator.filenames)) 
print("Loss: ", score[0], "Accuracy: ", score[1])

target_names = []

for key in train_generator.class_indices:

    target_names.append(key)



print(target_names)

Y_pred = model.predict_generator(test_generator)

y_pred = np.argmax(Y_pred, axis=1)

print('Confusion Matrix')

cm = confusion_matrix(test_generator.classes, y_pred)

print(cm)

print('Classification Report')

print(classification_report(test_generator.classes, y_pred, target_names=target_names))

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'Validation'], loc='upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'Validation'], loc='upper left')
plt.show()

pip install google.colab

import os, sys
from os import listdir
import numpy as np
from keras.preprocessing import image

import numpy as np
# from google.colab import files
from keras.preprocessing import image

uploaded = files.upload()

for fn in uploaded.keys():
 
  # predicting images
  path = fn
  img = image.load_img(path, target_size=(150, 150))
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)

  images = np.vstack([x])
  classes = model.predict(images, batch_size=10)
  print(fn)
  print(classes)

import numpy as np
from keras.preprocessing import image
import imageio as iio
test_image = tf.keras.preprocessing.image.load_img('./content/drive/MyDrive/preprocessed_images/test/class0/img2.00.jpg', target_size = (150, 150))
test_image = tf.keras.preprocessing.image.img_to_array(test_image)
test_image = np.expand_dims(test_image, axis = 0)
result = model.predict(test_image)
# training_set.class_indices
print(result[0][0])
if result[0][0] == 0:
  prediction = 'Normal'
else:
  prediction = 'Glaucoma'
print(prediction)

test_image = tf.keras.preprocessing.image.load_img('./content/drive/MyDrive/preprocessed_images/test/class1/img1.00.jpg', target_size = (150, 150))
test_image = tf.keras.preprocessing.image.img_to_array(test_image)
test_image = np.expand_dims(test_image, axis = 0)
result = model.predict(test_image)
# training_datagen.class_indices
print(result[0][0])
if result[0][0] == 0:
  prediction = 'Normal'
else:
  prediction = 'Glaucoma'
print(prediction)

import urllib.request
from PIL import Image
  
urllib.request.urlretrieve(
  'http://localhost:3000/uploads/glucomaImg/_incOP1DlhmOtVHbCxvIQ_278009919_532898738457411_1673914616059507264_n.jpg',
   "gfg.png")
  
img = Image.open("gfg.png")
print(img)
img.show()

imageUrl = 'http://localhost:3000/uploads/glucomaImg/_incOP1DlhmOtVHbCxvIQ_278009919_532898738457411_1673914616059507264_n.jpg'
def deploypredict(imageUrl):
  test_image = tf.keras.preprocessing.image.load_img(imageUrl, target_size = (150, 150))
  test_image = tf.keras.preprocessing.image.img_to_array(test_image)
  test_image = np.expand_dims(test_image, axis = 0)
  result = model.predict(test_image)
  # training_datagen.class_indices
  if result[0][0] == 0:
    prediction = 'Normal'
  else:
    prediction = 'Glaucoma'
  print(prediction)
  return prediction

model.save("my_model")

reconstructed_model =tf.keras.models.load_model("my_model")

test_image = tf.keras.preprocessing.image.load_img('./content/drive/MyDrive/preprocessed_images/test/class1/img2.00.jpg', target_size = (150, 150))
test_image = tf.keras.preprocessing.image.img_to_array(test_image)
test_image = np.expand_dims(test_image, axis = 0)
result = reconstructed_model.predict(test_image)
  # training_datagen.class_indices
if result[0][0] == 0:
    prediction = 'Normal'
else:
    prediction = 'Glaucoma'
print(prediction)

# pip install joblib

from joblib import dump, load

dump(model , 'g.sav')

import pickle
pickle_out = open("galucoma58.pkl","wb")
pickle.dump(model, pickle_out)
pickle_out.close()